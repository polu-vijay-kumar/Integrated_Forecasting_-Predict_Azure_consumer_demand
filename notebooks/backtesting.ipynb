{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc9b88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost statsmodels tensorflow scikit-learn --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55a44f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions: ['East US' 'West US' 'North Europe' 'Southeast Asia']\n",
      "Data shape: (1080, 38)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load full dataset\n",
    "\n",
    "data = pd.concat([\n",
    "    pd.read_csv(\"train.csv\", parse_dates=['date']),\n",
    "    pd.read_csv(\"val.csv\", parse_dates=['date']),\n",
    "    pd.read_csv(\"test.csv\", parse_dates=['date'])\n",
    "])\n",
    "data = data.sort_values(\"date\")\n",
    "\n",
    "print(\"Regions:\", data['Region'].unique())\n",
    "print(\"Data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce20800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Utility: Metrics\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return mae, rmse, mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8bf2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Backtesting - ARIMA\n",
    "# -------------------------------\n",
    "def backtest_arima(data, region, train_window, forecast_horizon, order=(5,1,0)):\n",
    "    region_data = data[data['Region']==region].groupby('date')['usage_cpu'].mean()\n",
    "    dates = region_data.index\n",
    "    metrics = []\n",
    "\n",
    "    if len(dates) <= train_window + forecast_horizon:\n",
    "        print(f\"⚠️ Not enough data for ARIMA in {region}\")\n",
    "        return []\n",
    "\n",
    "    for i in range(train_window, len(dates)-forecast_horizon, forecast_horizon):\n",
    "        train_series = region_data.iloc[:i]\n",
    "        test_series = region_data.iloc[i:i+forecast_horizon]\n",
    "\n",
    "        try:\n",
    "            model = ARIMA(train_series, order=order)\n",
    "            model_fit = model.fit()\n",
    "            forecast = model_fit.forecast(steps=forecast_horizon)\n",
    "\n",
    "            mae, rmse, mape = get_metrics(test_series, forecast)\n",
    "            metrics.append([region, \"ARIMA\", test_series.index[0], test_series.index[-1], mae, rmse, mape])\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ ARIMA failed in {region}: {e}\")\n",
    "            continue\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22b573b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Backtesting - XGBoost\n",
    "# -------------------------------\n",
    "def backtest_xgb(data, region, features, train_window, forecast_horizon, target='usage_cpu'):\n",
    "    region_data = data[data['Region']==region].copy().sort_values(\"date\")\n",
    "    dates = region_data['date'].unique()\n",
    "    metrics = []\n",
    "\n",
    "    if len(dates) <= train_window + forecast_horizon:\n",
    "        print(f\"⚠️ Not enough data for XGBoost in {region}\")\n",
    "        return []\n",
    "\n",
    "    for i in range(train_window, len(dates)-forecast_horizon, forecast_horizon):\n",
    "        train_dates = dates[:i]\n",
    "        test_dates = dates[i:i+forecast_horizon]\n",
    "\n",
    "        train_df = region_data[region_data['date'].isin(train_dates)]\n",
    "        test_df = region_data[region_data['date'].isin(test_dates)]\n",
    "\n",
    "        X_train, y_train = train_df[features], train_df[target]\n",
    "        X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=200, learning_rate=0.1, max_depth=6,\n",
    "            random_state=42, n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae, rmse, mape = get_metrics(y_test, y_pred)\n",
    "        metrics.append([region, \"XGBoost\", test_dates[0], test_dates[-1], mae, rmse, mape])\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97c7d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Backtesting - LSTM\n",
    "# -------------------------------\n",
    "def create_sequences(data, seq_length=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def backtest_lstm(data, region, train_window, forecast_horizon, seq_length=7):\n",
    "    region_series = data[data['Region']==region].groupby('date')['usage_cpu'].mean().values\n",
    "    metrics = []\n",
    "\n",
    "    if len(region_series) <= train_window + forecast_horizon:\n",
    "        print(f\"⚠️ Not enough data for LSTM in {region}\")\n",
    "        return []\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    region_scaled = scaler.fit_transform(region_series.reshape(-1,1))\n",
    "\n",
    "    for i in range(train_window, len(region_scaled)-forecast_horizon, forecast_horizon):\n",
    "        train_seq = region_scaled[:i]\n",
    "        test_seq = region_scaled[i-seq_length:i+forecast_horizon]\n",
    "\n",
    "        X_train, y_train = create_sequences(train_seq, seq_length)\n",
    "        X_test, y_test = create_sequences(test_seq, seq_length)\n",
    "\n",
    "        if len(X_test) == 0:\n",
    "            continue\n",
    "\n",
    "        # Define LSTM\n",
    "        model = Sequential([\n",
    "            LSTM(50, activation='relu', input_shape=(seq_length,1)),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=16, verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "        y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
    "        y_pred_inv = scaler.inverse_transform(y_pred).flatten()[:forecast_horizon]\n",
    "\n",
    "        mae, rmse, mape = get_metrics(y_test_inv[:forecast_horizon], y_pred_inv)\n",
    "        metrics.append([region, \"LSTM\", None, None, mae, rmse, mape])\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b048c30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏳ Backtesting East US: train_window=54, forecast_horizon=9\n",
      "\n",
      "⏳ Backtesting West US: train_window=54, forecast_horizon=9\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000175794B4180> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001757C6ADBC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "⏳ Backtesting North Europe: train_window=54, forecast_horizon=9\n",
      "\n",
      "⏳ Backtesting Southeast Asia: train_window=54, forecast_horizon=9\n"
     ]
    }
   ],
   "source": [
    "# 6. Run Adaptive Backtesting\n",
    "# -------------------------------\n",
    "all_metrics = []\n",
    "\n",
    "# Features for XGBoost\n",
    "exclude_cols = ['date','Region','ResourceType','usage_cpu',\n",
    "                'ResourceType_Storage','ResourceType_VM']\n",
    "features = [col for col in data.columns if col not in exclude_cols]\n",
    "\n",
    "for region in data['Region'].unique():\n",
    "    region_len = len(data[data['Region']==region]['date'].unique())\n",
    "\n",
    "    # Adaptive windows\n",
    "    train_window = max(30, int(region_len * 0.6))\n",
    "    forecast_horizon = max(7, int(region_len * 0.1))\n",
    "\n",
    "    print(f\"\\n⏳ Backtesting {region}: train_window={train_window}, forecast_horizon={forecast_horizon}\")\n",
    "\n",
    "    all_metrics.extend(backtest_arima(data, region, train_window, forecast_horizon))\n",
    "    all_metrics.extend(backtest_xgb(data, region, features, train_window, forecast_horizon))\n",
    "    all_metrics.extend(backtest_lstm(data, region, train_window, forecast_horizon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4b50ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Backtesting Completed!\n",
      "                              MAE       RMSE       MAPE\n",
      "Region         Model                                   \n",
      "East US        ARIMA     9.042368  10.427872  12.777746\n",
      "               LSTM      9.910331  12.231820  12.997841\n",
      "               XGBoost   0.064375   0.203382   0.104866\n",
      "North Europe   ARIMA     5.934640   7.294230   8.110310\n",
      "               LSTM     10.911699  12.449236  14.113892\n",
      "               XGBoost   0.011653   0.033567   0.013158\n",
      "Southeast Asia ARIMA     7.599975   9.261109  10.154881\n",
      "               LSTM     13.612378  15.782995  17.394923\n",
      "               XGBoost   0.002165   0.005533   0.002796\n",
      "West US        ARIMA     9.479601  10.721238  12.564169\n",
      "               LSTM     11.480525  13.527392  14.487433\n",
      "               XGBoost   0.060546   0.211460   0.074240\n"
     ]
    }
   ],
   "source": [
    "# 7. Save & Show Results\n",
    "# -------------------------------\n",
    "df_backtest = pd.DataFrame(all_metrics, columns=[\"Region\",\"Model\",\"Start\",\"End\",\"MAE\",\"RMSE\",\"MAPE\"])\n",
    "df_backtest.to_csv(\"backtest_metrics.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Backtesting Completed!\")\n",
    "print(df_backtest.groupby([\"Region\",\"Model\"]).mean(numeric_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
